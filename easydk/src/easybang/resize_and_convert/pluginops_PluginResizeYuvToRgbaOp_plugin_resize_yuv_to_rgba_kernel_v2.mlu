/*************************************************************************
 * Copyright (C) [2019] by Cambricon, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/
#include <mlu.h>
#include <algorithm>

#include "plugin_resize_yuv_to_rgba_macro.h"

#define MAX_SRCNUM 8192
#define BUFFER_SIZE 250 * 1024
#define SCALE 1.0
#define NORM 1.0
#define MULT_LIMIT 63 // wram limit
/*------------------------------ HELP FUNCTIONS ------------------------------*/
// load syn & bias from gdram if needed
// mult: the multipiler used in upscaling mode
__mlu_func__ void loadFilters(half* yuvSyn, half* yuvBias, half* cpySyn,
                              half* yuvFilter_gdram, half* yuvBias_gdram,
                              half* multFliter, half* buffer, int mult) {
  // Load weights if need src expansion
  if (mult > 1 && mult < MULT_LIMIT) {
    half* IdenCI = buffer;
    half* cpyFilter = IdenCI + CI * CI;
    __bang_write_zero(IdenCI, CI * CI);
    for (int i = 0; i < CI; i++) {
      ((int16_t*)IdenCI)[i * CI + i] = 1;
    }

    int kernelNum = mult * CI;
    int kernelNumPerLT = kernelNum / LT_NUM;
    for (int kernelId = 0; kernelId < kernelNum; kernelId++) {
      int ltId = kernelId % LT_NUM;
      int ltOffset = kernelId / LT_NUM;
      int filterOffset = ltId * kernelNumPerLT + ltOffset;
      int IdenOffset = 4 * (kernelId / (4 * mult)) + (kernelId % 4);
      __memcpy(cpyFilter + filterOffset * CI, IdenCI + IdenOffset * CI,
               CI * sizeof(half), NRAM2NRAM);
    }
    __memcpy(cpySyn, cpyFilter, CI * CI * mult * sizeof(half), NRAM2WRAM);
  }

  // Load bias/weights for yuv2rgb conv
  // int kernelLen = 2 * CI;
  __memcpy(yuvBias, yuvBias_gdram, CO * sizeof(half), GDRAM2NRAM);
  __memcpy(yuvSyn, yuvFilter_gdram, 2 * CI * CO * sizeof(half), GDRAM2WRAM);
}

// [Module 1]::genMaskAndWeights
// generate mask && weightX to select proper point column-wisely
// using the formula posSrc = (posDst + 0.5) * scale - 0.5
// integer part of posSrc will be the index
// fractional part of posSrc will be (1 - weight)
/*
 *      | wx0 | wx1 |
 * [Y0X0]-----------[Y0X1]
 *            |
 *        wy0 | wy0
 *            |
 *       -----------
 *            |
 *        wy1 | wy1
 *            |
 * [Y1X0]-----------[Y1X1]
 *
 */
__mlu_func__ void genMaskAndWeights(half* weightX, half* maskX0, half* maskX1,
                                    int maskNum, int scaleX, int PosX, int dstDealNum,
                                    int mult, int colLimit, int roi_x) {
  int posX = PosX;
  half fx = 0.0;    // fractional part
  int sx = 0;       // integer part
  half wx0 = 0.0;   // weight for left point
  half wx1 = 0.0;   // weight for right point
  int sxPrev = -1;  // prev integer part
  int jPrev = 0;    // the first new j
  int maskOffsetX0, maskOffsetX1;
  for (int j = 0; j < dstDealNum; j++) {
    // For each point in dst image, we can uniquely determine
    // four points in src image. In down-scaling mode, n dst points
    // has n distict src points, however in up-scaling mode, n dst
    // points can share 1 src points. This results in the replication
    // of src image later in the code.
    fx = (half)((posX & 0xFFFF) >> 1) / 32768 * (int)(posX > 0);
    sx = (posX >> 16) * (int)(posX > 0);
    // fx = fx * (int)(sx < colLimit);
    fx = fx * (int)(sx < (roi_x % 2 == 0 ? colLimit : colLimit - 1));
    sx = std::min(sx, colLimit);
    wx0 = (((half)1.f - fx) * SCALE);
    wx1 = (half)SCALE - wx0;
    posX += scaleX;

    // In up-scaling mode, we replicate each src row
    // by a certain number, mult. When generating the mask,
    // we must know which replication shall we use since they
    // represent the same pixel. Thus we need a variable to
    // [recrod the position of first new pixel], i.e., jPrev.
    jPrev = j * (sxPrev != sx) + jPrev * (sxPrev == sx);
    sxPrev = sx;
    int offsetW0 = j * 4;
    int offsetW1 = (j + dstDealNum) * 4;
    int trueIdx0 = 0;
    int trueIdx1 = 0;
    if (roi_x % 2 == 0) {
      trueIdx0 = (sx * mult + (j - jPrev)) * 4;
      trueIdx1 = ((sx + 1) * mult + (j - jPrev)) * 4;
    } else {
      trueIdx0 = (sx * mult + (j - jPrev)) * 4 + 4 * mult;
      trueIdx1 = ((sx + 1) * mult + (j - jPrev)) * 4 + 4 * mult;
    }
    for (int k = 0; k < 4; k++) {
      weightX[offsetW0++] = wx0;
      weightX[offsetW1++] = wx1;
      if (trueIdx0 < maskNum)
        maskX0[trueIdx0++] = 1;
      if (trueIdx1 < maskNum)
        maskX1[trueIdx1++] = 1;
    }
  }
}

__mlu_func__ int find_limit(int roi_w, int d_col, int mult, int channel) {
  int lower_bound = 0;
  int upper_bound = d_col + 1;
  while (lower_bound < upper_bound - 1) {
    int size = (lower_bound + upper_bound) / 2;
    int size_pad = PAD_UP(size * channel, PAD_SIZE) / channel;

    int src_size = std::min(roi_w + PAD_SIZE,
                       roi_w * (size_pad - 1) / d_col + 2 + PAD_SIZE / channel);
    int src_size_pad = PAD_UP(src_size * channel, PAD_SIZE) / channel;

    int malloc_size = (2 * mult * src_size_pad + 2 * size_pad +
                       std::max(4 * size_pad, 2 * src_size_pad) +
                       std::max(4 * size_pad, 2 * mult * src_size_pad)) *
                          channel * 2 +
                      2 * MAX_SRCNUM;
    if (malloc_size <= 2 * BUFFER_SIZE)  // half
      lower_bound = size;
    else
      upper_bound = size;
  }
  return lower_bound;
}

/*---------------------------- MLU ENTRY FUNCTION ----------------------------*/
/*!
 *  @brief A function.
 *
 *  A fusionOp of resize and yuv2rgb
 *
 *  **Supports MLU220/MLU270**
 *
 *  @param[out] dst_gdram
 *    Output. dst image addrs in gdram.
 *  @param[in]  srcY_gdram
 *    Input. src image Y channel addrs in gdram.
 *  @param[in]  srcUV_gdram
 *    Input. src image UV channel addrs in gdram.
 *  @param[in]  srcWH_gdram
 *    Input. src image size in gdram.
 *  @param[in]  roiRect_gdram
 *    Input. roi Rect of src image in gdram.
 *  @param[in]  fill_color_gdram
 *    Input. the fill color of pad when keep aspect ratio.
 *  @param[in]  yuvFilter_gdram
 *    Input. the filter used to do yuv2rgb conversion.
 *  @param[in]  yuvBias_gdram
 *    Input. the bias needed by yuv2rgb conversion.
 *  @param[in]  d_row
 *    Input. number of row of dst image.
 *  @param[in]  d_col
 *    Input. number of col of dst image.
 *  @param[in]  intput2half
 *    Input. 1 for uint8 input, 0 for fp16 input.
 *  @param[in]  output2uint
 *    Input. 1 for uint8 output, 0 for fp16 output.
 *  @param[in]  batchNum
 *    Input. batch number.
 */
#if __BANG_ARCH__ > 220
__mlu_entry__ void ResizeYuvToRgbaKernel_V2_MLU270(
#elif __BANG_ARCH__ >= 200
__mlu_entry__ void ResizeYuvToRgbaKernel_V2_MLU220(
#endif
    half* dst_gdram,
    half** srcY_gdram,
    half** srcUV_gdram,
    int** srcWH_gdram,
    int** roiRect_gdram,
    half* fill_color_gdram,
    half* yuvFilter_gdram,
    half* yuvBias_gdram,
    int d_row_final, int d_col_final,
    int input2half, int output2uint,
    int batchNum,
    int keepAspectRatio,
    int padMethod) {
#if (__BANG_ARCH__ >= 200) && (__RECORD_TIME__ >= 1)
  struct timeval tstart;
  struct timeval tend;
  gettimeofday(&tstart, NULL);
#endif
  /**---------------------- Initialization ----------------------**/

  __wram__ half yuvSyn[2 * CI * CO];
#if __BANG_ARCH__ == 220
  __wram__ half cpySyn[64 * 64 * 50];
#elif __BANG_ARCH__ == 270
  __wram__ half cpySyn[64 * 64 * 100];
#endif
  __nram__ half buffer[BUFFER_SIZE + 2 * CO];
  __nram__ half round[64];

  int startBatch = 0;
  int endBatch = 0;
  if (batchNum % taskDim == 0) {
    startBatch = taskId * (batchNum / taskDim);
    endBatch = startBatch + (batchNum / taskDim);
  } else {
    startBatch = 0;
    endBatch = batchNum;
  }

  // for batchNum
  for (int batch = startBatch; batch < endBatch; batch++) {

    int s_col = srcWH_gdram[batch][0];
    int s_row = srcWH_gdram[batch][1];
    int roi_x = roiRect_gdram[batch][0];
    int roi_y = roiRect_gdram[batch][1];
    int roi_w = roiRect_gdram[batch][2];
    int roi_h = roiRect_gdram[batch][3];
    int roi_x_ = roi_x / 2 * 2;

    int d_row = 0;
    int d_col = 0;
    int scaleX = 0;
    int scaleY = 0;
    int pad_mode = 0;
    int pad_half1 = 0;
    int pad_half2 = 0;
    float src_aspect_ratio = 0;
    float dst_aspect_ratio = 0;

    // only YUV2RGB0?
    int only_yuv2rgba = 0;
    only_yuv2rgba = (roi_w == d_col_final && roi_h == d_row_final);

    src_aspect_ratio = (float)roi_w / roi_h;
    dst_aspect_ratio = (float)d_col_final / d_row_final;
    if (keepAspectRatio && only_yuv2rgba == 0 && (src_aspect_ratio != dst_aspect_ratio)) {
      if (src_aspect_ratio >= dst_aspect_ratio) {
        // pad top && bottom
        d_col = d_col_final;
        d_row = __float2int_rd(d_col_final / src_aspect_ratio);
        pad_mode = 0;
        if (padMethod == 0) {
          pad_half1 = (d_row_final - d_row) / 2;
          pad_half2 = d_row_final - d_row - pad_half1;
        } else if (padMethod == 1) {
          pad_half1 = 0;
          pad_half2 = d_row_final - d_row;
        }

        if (taskDim == 1 && coreId != 0x80) {
          unsigned char* item_line = (unsigned char*)buffer;
          unsigned char* fill_line = item_line + 4;

          ((unsigned char*)item_line)[0] = ((unsigned char*)fill_color_gdram)[0];
          ((unsigned char*)item_line)[1] = ((unsigned char*)fill_color_gdram)[1];
          ((unsigned char*)item_line)[2] = ((unsigned char*)fill_color_gdram)[2];
          ((unsigned char*)item_line)[3] = 0;

          __memcpy(fill_line,
                   item_line,
                   4,
                   NRAM2NRAM,
                   4,
                   0,
                   d_col - 1);
          // fill top
          if (pad_half1 != 0) {
            __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4,
                     fill_line,
                     d_col * 4,
                     NRAM2GDRAM,
                     d_col * 4,
                     0,
                     pad_half1 - 1);
          }
          // fill bottom
          if (pad_half2 != 0) {
            __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4 +
                     (d_row + pad_half1) * d_col * 4,
                     fill_line,
                     d_col * 4,
                     NRAM2GDRAM,
                     d_col * 4,
                     0,
                     pad_half2 - 1);
          }
        }
        if (taskDim != 1 && coreId == 0x80) {
          __mlu_shared__ unsigned char fill_sram[40000];
          unsigned char* item_line = fill_sram;
          unsigned char* fill_line = item_line + 4;

          item_line[0] = ((unsigned char*)fill_color_gdram)[0];
          item_line[1] = ((unsigned char*)fill_color_gdram)[1];
          item_line[2] = ((unsigned char*)fill_color_gdram)[2];
          item_line[3] = 0;

          __memcpy(fill_line,
                   item_line,
                   4,
                   SRAM2SRAM,
                   4,
                   0,
                   d_col - 1,
                   clusterId);

          if (batchNum % taskDim == 0) {
            int fillStartBatch = clusterId * (batchNum / clusterDim);
            int fillEndBatch = fillStartBatch + (batchNum / clusterDim);
            for (int fill_batch = fillStartBatch; fill_batch < fillEndBatch; fill_batch++) {
              // fill top
              if (pad_half1 != 0) {
                __memcpy((unsigned char*)dst_gdram + fill_batch * d_row_final * d_col_final * 4,
                         fill_line,
                         d_col * 4,
                         SRAM2GDRAM,
                         d_col * 4,
                         0,
                         pad_half1 - 1);
              }
              // fill bottom
              if (pad_half2 != 0) {
                __memcpy((unsigned char*)dst_gdram + fill_batch * d_row_final * d_col_final * 4 +
                         (d_row + pad_half1) * d_col * 4,
                         fill_line,
                         d_col * 4,
                         SRAM2GDRAM,
                         d_col * 4,
                         0,
                         pad_half2 - 1);
              }
            }
          } else {
            // fill top
            if (pad_half1 != 0) {
              __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4,
                       fill_line,
                       d_col * 4,
                       SRAM2GDRAM,
                       d_col * 4,
                       0,
                       pad_half1 - 1);
            }
            // fill bottom
            if (pad_half2 != 0) {
              __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4 +
                       (d_row + pad_half1) * d_col * 4,
                       fill_line,
                       d_col * 4,
                       SRAM2GDRAM,
                       d_col * 4,
                       0,
                       pad_half2 - 1);
            }
          }
        }
      } else { // src_aspect_ratio >= dst_aspect_ratio
        // pad left && right
        d_row = d_row_final;
        d_col = __float2int_rd(d_row * src_aspect_ratio);
        pad_mode = 1;
        if (padMethod == 0) {
          pad_half1 = (d_col_final - d_col) / 2;
          pad_half2 = d_col_final - d_col - pad_half1;
        } else if (padMethod == 1) {
          pad_half1 = 0;
          pad_half2 = d_col_final - d_col;
        }

        if (taskDim == 1 && coreId != 0x80) {
          unsigned char* left_line = (unsigned char*)buffer;
          unsigned char* right_line = (unsigned char*)buffer + pad_half1 * 4;

          for (int i = 0; i < pad_half1; i++) {
            left_line[i * 4 + 0] = ((unsigned char*)fill_color_gdram)[0];
            left_line[i * 4 + 1] = ((unsigned char*)fill_color_gdram)[1];
            left_line[i * 4 + 2] = ((unsigned char*)fill_color_gdram)[2];
            left_line[i * 4 + 3] = 0;
          }
          for (int i = 0; i < pad_half2; i++) {
            right_line[i * 4 + 0] = ((unsigned char*)fill_color_gdram)[0];
            right_line[i * 4 + 1] = ((unsigned char*)fill_color_gdram)[1];
            right_line[i * 4 + 2] = ((unsigned char*)fill_color_gdram)[2];
            right_line[i * 4 + 3] = 0;
          }
          // fill left
          if (pad_half1 != 0) {
            __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4,
                     left_line,
                     pad_half1 * 4,
                     NRAM2GDRAM,
                     d_col_final * 4,
                     0,
                     d_row - 1);
          }
          // fill right
          if (pad_half2 != 0) {
            __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4 + (d_col + pad_half1) * 4,
                     right_line,
                     pad_half2 * 4,
                     NRAM2GDRAM,
                     d_col_final * 4,
                     0,
                     d_row - 1);
          }
        }
        if (taskDim != 1 && coreId == 0x80) {
          __mlu_shared__ unsigned char buffer_sram[20000];
          unsigned char* left_line = (unsigned char*)buffer_sram;
          unsigned char* right_line = (unsigned char*)buffer_sram + pad_half1 * 4;

          for (int i = 0; i < pad_half1; i++) {
            left_line[i * 4 + 0] = ((unsigned char*)fill_color_gdram)[0];
            left_line[i * 4 + 1] = ((unsigned char*)fill_color_gdram)[1];
            left_line[i * 4 + 2] = ((unsigned char*)fill_color_gdram)[2];
            left_line[i * 4 + 3] = 0;
          }
          for (int i = 0; i < pad_half2; i++) {
            right_line[i * 4 + 0] = ((unsigned char*)fill_color_gdram)[0];
            right_line[i * 4 + 1] = ((unsigned char*)fill_color_gdram)[1];
            right_line[i * 4 + 2] = ((unsigned char*)fill_color_gdram)[2];
            right_line[i * 4 + 3] = 0;
          }
          if (batchNum % taskDim == 0) {
            int fillStartBatch = clusterId * (batchNum / clusterDim);
            int fillEndBatch = fillStartBatch + (batchNum / clusterDim);
            for (int fill_batch = fillStartBatch; fill_batch < fillEndBatch; fill_batch++) {
              // fill left
              if (pad_half1 != 0) {
                __memcpy((unsigned char*)dst_gdram + fill_batch * d_row_final * d_col_final * 4,
                         left_line,
                         pad_half1 * 4,
                         SRAM2GDRAM,
                         d_col_final * 4,
                         0,
                         d_row - 1);
              }
              // fill right
              if (pad_half2 != 0) {
                __memcpy((unsigned char*)dst_gdram + fill_batch * d_row_final * d_col_final * 4 + (d_col + pad_half1) * 4,
                         right_line,
                         pad_half2 * 4,
                         SRAM2GDRAM,
                         d_col_final * 4,
                         0,
                         d_row - 1);
              }
            }
          } else {
            // fill left
            if (pad_half1 != 0) {
              __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4,
                       left_line,
                       pad_half1 * 4,
                       SRAM2GDRAM,
                       d_col_final * 4,
                       0,
                       d_row - 1);
            }
            // fill right
            if (pad_half2 != 0) {
              __memcpy((unsigned char*)dst_gdram + batch * d_row_final * d_col_final * 4 + (d_col + pad_half1) * 4,
                       right_line,
                       pad_half2 * 4,
                       SRAM2GDRAM,
                       d_col_final * 4,
                       0,
                       d_row - 1);
            }
          }
        }
      } // src_aspect_ratio < dst_aspect_ratio
    } else { // keepAspectRatio
      d_row = d_row_final;
      d_col = d_col_final;
    } // keepAspectRatio
    scaleX = (roi_w << 16) / d_col;
    scaleY = (roi_h << 16) / d_row;

    // divide large d_col into repeats * dstDealNum + dstRemainder
    int d_col_pad = PAD_UP(d_col * 4, PAD_SIZE) / 4;
    int mult = (int)(roi_w < d_col) * (98304 + (scaleX >> 1)) / scaleX +
               (int)(roi_w >= d_col);
    int limit = find_limit(roi_w, d_col, mult, 4);
    int dstDealNum = PAD_UP(limit * 4, PAD_SIZE) / 4;

    int repeat = d_col / dstDealNum;
    int remainder = d_col % dstDealNum;
    if (repeat != 0 && remainder == 0) {
      repeat -= 1;
      remainder = dstDealNum;
    }
    int remainderPad = PAD_UP(remainder * 4, PAD_SIZE) / 4;
    /*
     *  src_length = dst_length * scale
     *             = dst_length * roi_w / d_col
     *         ______________________
     *        /                      \
     *       /                        \
     *      /                          \
     *     /                            \
     *    /_____________________________ \
     *    dst_length = dstDealNum - 1
     *
     *  srcDealNum = src_length + 1(length_to_point)
     *             + 2(pre&post) + aligned_bytes / c - 1
     */

    int srcDealNum = 0;
    if (roi_x % 2 == 0) {
      srcDealNum = (roi_w % 2 == 0 ? roi_w : roi_w + 1);
    } else {
      srcDealNum = (roi_w % 2 == 0 ? roi_w + 2 : roi_w + 1);
    }
    int srcDealNumPad = PAD_UP(srcDealNum, PAD_SIZE);

    // Multi-core related params
    // Two strategies are used
    int d_row_seg = 0;
    int d_row_core = 0;
    if (batchNum % taskDim == 0) {
      d_row_seg = d_row;
      d_row_core = d_row;
    } else {
      d_row_seg = d_row / taskDim + int(d_row % taskDim != 0);
      if (d_row % taskDim == 0) {
        d_row_core = d_row_seg;
      } else {
        int tmp = d_row / d_row_seg;
        if (taskId < tmp)
          d_row_core = d_row_seg;
        else if (taskId == tmp)
          d_row_core = d_row - tmp * d_row_seg;
        else
          d_row_core = 0;
      }
    }

    // Memory usage
    // Put all const variables(bias, weight, mask) at front of the buffer
    // so that space after them can be used freely without concerning
    // overwritting const variables
    int srcNum = srcDealNumPad * 4;
    int dstNum = dstDealNum * 4;
    int dstNumPad = PAD_UP(dstDealNum * 4, PAD_SIZE);
    int weightNum = dstNum * 2;
    int maskNum = srcNum * mult;
    half* temp = buffer;
    half* yuvBias = buffer + CO;
    half* weightX = yuvBias + CO;
    half* maskUV = weightX + weightNum;
    half* maskX0 = maskUV + MAX_SRCNUM;
    half* maskX1 = maskX0 + maskNum;
    half* src = maskX1 + maskNum + 64;
    half* sLine0 = src + std::max(4 * dstNum, maskNum * 2);
    half* sLine1 = sLine0 + std::max(2 * dstNum, srcNum);
    half* dstBuffer = sLine1 + std::max(std::max(2 * dstNum, srcNum) + 64,
                                        dstNum + maskNum);

    int rowCopyNum = (BUFFER_SIZE - (int)(dstBuffer - temp)) / dstNum;
    rowCopyNum = std::min(rowCopyNum, d_row_seg) / 2 * 2;
    int dstCount = 0;
    // rowCopyNum = 1;

    for (int i = 0; i < 16; i++) {
      round[i * 4 + 0] = 0.5;
      round[i * 4 + 1] = 0.5;
      round[i * 4 + 2] = 0.5;
      round[i * 4 + 3] = 0.0;
    }
    // Load filter/bias
    loadFilters(yuvSyn, yuvBias, cpySyn, yuvFilter_gdram, yuvBias_gdram, src,
                buffer, mult);

    /**----------------------- convert and resize -----------------------**/
    int dstSize = dstNum * sizeof(half);
    int dstRGBASizePerBatch = d_col_final * d_row_final * 4;

    ////// for batch position if src size is same //////
    half* srcYAddrsBat = srcY_gdram[batch];
    half* srcUVAddrsBat = srcUV_gdram[batch];
    int batch_start_offset = 0;
    if (keepAspectRatio == 0) {
      batch_start_offset = 0;
    } else {
      if (pad_mode == 0) {
        batch_start_offset = pad_half1 * d_col * 4;
      } else {
        batch_start_offset = pad_half1 * 4;
      }
    }
    half* dstRGBAAddrsBat =
        dst_gdram + (batch * dstRGBASizePerBatch + batch_start_offset +
        d_row_seg * d_col_final * 4 * taskId * (d_row_seg < d_row)) / (output2uint + 1);
    int rowLimit = roi_h - 1;
    int colLimit = 0;
    if (roi_x % 2 == 0) {
      colLimit = roi_w - 1;
    } else {
      colLimit = (roi_w % 2 == 0 ? roi_w + 1 : roi_w);
    }

#ifdef ZERO_COORDINATE
    int posX = 0;
#else
    int posX = scaleX / 2 - 32768;
#endif

    for (int i = 0; i < repeat + 1 /* remainder */; i++) {
      /* dstDealNum part
       * d_col = dstDealNum * repeat + dstRemainder
       * | dstDealNum_00 | dstDealNum_01| ... | dstRemainder_0 |
       *   .               .                    .
       *   .               .                    .
       *   .               .                    .
       * | dstDealNum_N0 | dstDealNum_N1| ... | dstRemainder_N |
       *
       * Note: dstDealNum_00 ... dstDealNum_N0 share the same mask and weights
       * so the order of LOAD/COMP/STORE looks like:
       * |   /|   /|  ...
       * |  / |  / |  ...
       * | /  | /  |  ...
       * |/   |/   |/ ...
       */
      /*###############################*/
      /*#[Module 1]: genMaskAndWeights#*/
      /*###############################*/
      __bang_write_zero(maskX0, srcNum * mult);
      __bang_write_zero(maskX1, srcNum * mult);
      genMaskAndWeights(weightX, maskX0, maskX1,
                        maskNum, scaleX, posX, dstDealNum, mult, colLimit, roi_x);
      __nramset_short((int16_t*)maskUV, MAX_SRCNUM, 0xFFFF);

      /*############################################*/
      /*#[Module 2]: loadTwoLines(Four in YUV mode)#*/
      /*############################################*/
      // posY and finalPosY locate which segment of src
      // resizeOp is dealing with (multi-core support)
      // fy(fractional part of posY) records the weight
      // sy(integer part of posY) records the position
#ifdef ZERO_COORDINATE
      int posY = (d_row_seg * taskId * (d_row_seg < d_row)) * scaleY;
#else
      int posY = (d_row_seg * taskId * (d_row_seg < d_row)) * scaleY +
                 (scaleY >> 1) - 32768;
#endif
      int finalPosY = posY + (d_row_seg - 1) * scaleY;
      half fy = 0.0;
      int sy = 0;
      half wy0 = 0.0;
      half wy1 = 0.0;
      for (int j = 0; j < d_row_core; ++j) {
        if (only_yuv2rgba) {
          sy = (batchNum % taskDim != 0) * taskId * d_row_seg + j;
        } else {
          sy = (posY >> 16) * (int)(posY > 0);
          sy = std::max(std::min(sy, rowLimit - 1), 0) + roi_y;
        }

        // compute offsets for each row
        int offsetY1 = (sy * s_col) + roi_x_;
        int offsetY2 = ((sy + 1) * (roi_h != 1) + sy * (roi_h == 1)) * s_col + roi_x_;
        int offsetUV1 = (sy / 2) * s_col + roi_x_;
        int offsetUV2 = (((sy + 1) / 2) * (roi_h != 1) + (sy / 2) * (roi_h == 1)) * s_col + roi_x_;

        if (input2half) {
          /*#################################*/
          /*#[Module 3]: Preprocess(For YUV)#*/
          /*#################################*/
          int dealNum = srcDealNumPad;
          int loadSize = srcDealNum * sizeof(char);
          int dealSize = dealNum * sizeof(char);
          half* Y = sLine0;
          char* UV = (char*)Y + 2 * dealNum;

          // Load two lines of Y and two line of UV
          __memcpy(Y, (char*)srcYAddrsBat + offsetY1, loadSize, GDRAM2NRAM);
          __memcpy(UV, (char*)srcUVAddrsBat + offsetUV1, loadSize, GDRAM2NRAM);
          if (!only_yuv2rgba) {
            __memcpy((char*)Y + dealNum, (char*)srcYAddrsBat + offsetY2, loadSize,
                     GDRAM2NRAM);
            __memcpy((char*)UV + dealNum, (char*)srcUVAddrsBat + offsetUV2,
                     loadSize, GDRAM2NRAM);
          }
          __bang_uchar2half(src, (unsigned char*)Y, dealNum * 4);

          /*######################*/
          /*#[Module 4]: YUV2RGB0#*/
          /*######################*/
          /* Fold input YUV data so that the input channel becomes CI(32)
           * Memory is continuous in this (-->) direction (in_width /= CI)
           * [Y1,1 Y1,2 ... Y1,31 Y1,32] ... [Y2,1 Y2,2 ... Y2,31 Y2,32] ...
           * [U1,1 V1,1 ... U1,16 V1,16] ... [U2,1 U2,2 ... U2,16 V2,16] ...
           * Input shape: 1(N) x 2(H) x s_col/CI(W) x CI(C)
           *
           * For each CI of input, we need 4 X CI kernels to convert
           * CI gray pixcels into 4 X CI RGBA pixcels. Each kernel has
           * a shape of: 1 x 2 x 1 x CI. For example,
           * [ 1.164  0     0 ... 0] -> 1.164 * Y1,1 -> R1,1
           * [ 0      1.586   ... 0]  + 1.586 * V1,1
           * [ 1.164  0     0 ... 0] -> 1.164 * Y1,1 -> G1,1
           * [-0.392 -0.813 0 ... 0]  - 0.392 * U1,1
           *                          - 0.813 * V1,1
           * ...
           * ...
           * [ 0 0 1.164 0     0 ... 0] -> 1.164 * Y1,3 -> R1,3
           * [ 0 0 0     1.586 0 ... 0]  + 1.586 * V1,2
           * ...
           * Total 4 X CI pixcels hence 4 X CI kernels
           */
          // conv params in order
          // in_channel = CI;
          // in_height = 2;
          // in_width = srcDealNumPad * 2 / CI;
          // filter_height = 2;
          // filter_width = 1;
          // stride_height = 1;
          // stride_width = 1;
          // out_channel = CO;
          __bang_half2fix16_rd((int16_t*)sLine0, src, srcDealNumPad * 4, -7);
          __bang_conv(src, (int16_t*)sLine0, (int16_t*)yuvSyn, CI, 2,
                      srcDealNumPad * 2 / CI, 2, 1, 1, 1, CO, -20);

          // truncate values < 0
          __bang_cycle_add(src, src, yuvBias, srcNum * 2, CO);
          __bang_active_relu(src, src, srcNum * 2);

          // truncate values > 255
          __nramset_half(temp, 64, 255);
          __bang_cycle_sub(src, src, temp, srcNum * 2, 64);
          __bang_mul_const(src, src, -1, srcNum * 2);
          __bang_active_relu(src, src, srcNum * 2);
          __bang_mul_const(src, src, -1, srcNum * 2);
          __bang_cycle_add(src, src, temp, srcNum * 2, 64);

          // Normalize RGB values so that interp weights can be multiplied and
          // be more accurate
          if (mult > 1) {
            __bang_mul_const(sLine0, src, 1 / NORM, srcNum * 2);
          } else {
            __bang_mul_const(src, src, 1 / NORM, srcNum * 2);
          }
        }

        if (only_yuv2rgba) {
          half* dst = src;
          half* dstMask = dst + PAD_UP(dstNum / 4, PAD_SIZE) * 4;

          if (output2uint) {
            __nramset_half(temp, 64, 1);
            __nramset_half(temp, 64, 127);
            __bang_cycle_gt(dstMask, dst, temp, PAD_UP(dstNum / 4, 64) * 4, 64);
            __bang_mul_const(dstMask, dstMask, 256, dstNum);
            __bang_sub(dstMask, dst, dstMask, dstNum);
            __bang_half2uchar_dn((signed char*)dstBuffer + dstCount * dstNumPad,
                                 dstMask, PAD_UP(dstNum, 128));
          }
          dstCount += 1;

          // if dstBuffer is full, copy out
          if (dstCount == rowCopyNum) {
            __memcpy(dstRGBAAddrsBat + i * dstDealNum,  // srcAddrs in gdram
                     dstBuffer,                         // srcAddrs in nram
                     d_col * 4,      // copy size for each segment
                     NRAM2GDRAM,     // direction
                     d_col_final * 4,      // dst stride, should be equal to copy size
                     dstNumPad,      // src stride
                     rowCopyNum - 1  // number of segment
            );
            dstRGBAAddrsBat += d_col_final * 2 * rowCopyNum;
            dstCount = 0;
          }
        } else {
          /*#################################*/
          /*#[Module 5]: src image expansion#*/
          /*#################################*/
          if (mult > 1 && mult < MULT_LIMIT) {
            half* Y = sLine0 + srcDealNumPad * 8;
            __bang_half2fix16_rd((int16_t*)Y, sLine0, srcDealNumPad * 8, -7);
            __bang_conv(src, (int16_t*)Y, (int16_t*)cpySyn, CI, 1,
                        srcDealNumPad * 8 / CI, 1, 1, 1, 1, CI * mult, -7);
          } else if (mult >= MULT_LIMIT) {
            for (int m = 0; m < mult; m++) {
              __memcpy(src + m * 4,
                       sLine0,
                       4 * sizeof(half),
                       NRAM2NRAM,
                       mult * 4 * sizeof(half),
                       4 * sizeof(half),
                       mult - 1);
            }
          }

          // Select data using the mask gegerated in [1]
          // For example,
          /* Before:
           * [Y0X0 Y0X1] ... [Y0X4 Y0X5] ... [Y0X8 Y0X9] ...
           * [Y1X0 Y1X1] ... [Y1X4 Y1X5] ... [Y1X8 Y1X9] ...
           *  .    .          .    .          .    .
           *  .    .          .    .          .    .
           *
           * After:
           * Y0X0 Y0X4 Y0X8 ... Y0X1 Y0X5 Y0X9 ...
           * Y1X0 Y1X4 Y1X8 ... Y1X1 Y1X5 Y1X9 ...
           * .    .    .        .    .    .
           * .    .    .        .    .    .
           */
          __bang_collect(sLine0, src, maskX0, maskNum);
          __bang_collect(sLine0 + dstNum, src, maskX1, maskNum);
          __bang_collect(sLine1, src + maskNum, maskX0, maskNum);
          __bang_collect(sLine1 + dstNum, src + maskNum, maskX1, maskNum);

          int NextPosY = std::min(((posY >> 16) + 1) << 16, finalPosY);
          int srcReuseNum = std::max(1, (NextPosY - posY) / scaleY);
          for (int srcReuse = 0; srcReuse < srcReuseNum; srcReuse++) {
            int trueRowIdx = d_row_seg * taskId * (d_row_seg < d_row) + j;
            // move calculation from [Module 2] to here to optimize
            // up-sclaing mode.
            fy = (half)((posY & 0xFFFF) >> 1) / 32768 * (int)(posY > 0);
            sy = (posY >> 16) * (int)(posY > 0);
            fy = fy * (int)(sy < rowLimit) + (int)(sy == rowLimit);
            wy0 = (((half)1.f - fy) * SCALE);
            wy1 = (half)SCALE - wy0;
            posY += scaleY;
            /*####################################*/
            /*#[Module 6]. Bilinear Interpolation#*/
            /*####################################*/
            // x_star0 = Y0X0 * wx0 + Y0X1 * wx1
            half* dstLine0 = src;
            half* dstLine1 = dstLine0 + 2 * dstNum;
            __bang_mul(dstLine0, sLine0, weightX, dstNum * 2);
            __bang_add(dstLine0, dstLine0, dstLine0 + dstNum, dstNum);

            // x_star1 = Y1X0 * wx0 + Y1X1 * wx1
            __bang_mul(dstLine1, sLine1, weightX, dstNum * 2);
            __bang_add(dstLine1, dstLine1, dstLine1 + dstNum, dstNum);

            // x_star = x_star0 * wy0 + x_star1 * wy1
            __bang_mul_const(dstLine0, dstLine0, wy0, dstNum);
            __bang_mul_const(dstLine1, dstLine1, wy1, dstNum);
            __bang_add(dstLine0, dstLine0, dstLine1, dstNum);
            __bang_mul_const(dstLine0, dstLine0, 1.0 / SCALE, dstNum);
            __bang_mul_const(dstLine0, dstLine0, 1.0 / SCALE, dstNum);
            __bang_mul_const(dstLine0, dstLine0, NORM, dstNum);

            // acuracy compensation
            __bang_cycle_add(dstLine0, dstLine0, round, dstDealNum * 4, 64);

            /*##################################################################*/
            /*#[Module 7]: Postprocess && Store Data(Depadding not implemented)#*/
            /*##################################################################*/
            half* dst = dstLine0;
            half* dstMask = dst + PAD_UP(dstNum / 4, PAD_SIZE) * 4;

            if (output2uint) {
              __nramset_half(temp, 64, 1);
              __nramset_half(temp, 64, 127);
              __bang_cycle_gt(dstMask, dst, temp, PAD_UP(dstNum / 4, 64) * 4, 64);
              __bang_mul_const(dstMask, dstMask, 256, dstNum);
              __bang_sub(dstMask, dst, dstMask, dstNum);
              __bang_half2uchar_dn((signed char*)dstBuffer + dstCount * dstNumPad,
                                   dstMask, PAD_UP(dstNum, 128));
            }
            dstCount += 1;

            // if dstBuffer is full, copy out
            if (dstCount == rowCopyNum) {
              __memcpy(dstRGBAAddrsBat + i * dstDealNum,  // srcAddrs in gdram
                       dstBuffer,                         // srcAddrs in nram
                       d_col * 4,      // copy size for each segment
                       NRAM2GDRAM,     // direction
                       d_col_final * 4,      // dst stride, should be equal to copy size
                       dstNumPad,      // src stride
                       rowCopyNum - 1  // number of segment
              );
              dstRGBAAddrsBat += d_col_final * 2 * rowCopyNum;
              dstCount = 0;
            }
            j += (int)(srcReuseNum > 0);
          }
          j -= (int)(srcReuseNum > 0);

        } // only_yuv2grba
      } // for j

      posX += dstDealNum * scaleX;

      // if dstBuffer is not empty, copy out
      if (d_row_core % rowCopyNum > 0) {
        __memcpy(dstRGBAAddrsBat,
                dstBuffer,
                d_col * 4,
                NRAM2GDRAM,
                d_col_final * 4,
                dstNumPad,
                (d_row_core % rowCopyNum) - 1);
      }
      dstCount = 0;
    } // for i
  } // for batch
#if (__BANG_ARCH__ >= 200) && (__RECORD_TIME__ >= 1)
  gettimeofday(&tend, NULL);
  uint32_t time_usec = (uint32_t)tend.tv_usec - (uint32_t)tstart.tv_usec;
  uint32_t time_sec = (uint32_t)tend.tv_sec - (uint32_t)tstart.tv_sec;
  printf("Hardware Total Time: %u us\n", time_usec);
#endif
}
